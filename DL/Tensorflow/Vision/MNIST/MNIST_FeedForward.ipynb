{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST FeedForward.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEmRm2kfMVsw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NCFF-r0qIhs"
      },
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets \n",
        "from torchvision.transforms import ToTensor \n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z4YHC5JbCI8"
      },
      "source": [
        "path1 = \"/content/drive/MyDrive/Dataset\"\n",
        "path2 = \"/content/drive/MyDrive/Models/Pytorch/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DqD0lywc8zU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vycitnlZbHJ",
        "outputId": "5205412c-6234-4977-f945-521fa2fc94d9"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "print(f\"available {device} device \")\n",
        "\n",
        "device = torch.device(device)\n",
        "\n",
        "class FeedForwardNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dense_layers = nn.Sequential(\n",
        "        nn.Linear(28*28, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 10 )\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, input_data):  #indicates pytorch how to manipulate the data\n",
        "    flattened_data = self.flatten(input_data)\n",
        "    logits = self.dense_layers(flattened_data)\n",
        "    predictions = self.softmax(logits)\n",
        "    return predictions\n",
        "\n",
        "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
        "  for inputs, targets in data_loader:\n",
        "    inputs , targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # calculate loss\n",
        "    preds = model(inputs)\n",
        "    loss = loss_fn(preds,targets)\n",
        "\n",
        "    # backpropagate loss and update weights\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "  print(f\"loss : {loss.item()}\")\n",
        " \n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "  for i in range(epochs):\n",
        "    print(f\"epoch {i+1}\")\n",
        "    train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
        "    print(\"------------------------\")\n",
        "  print(\"training done\")\n",
        "\n",
        "def download_mnist_datasets(path,download=True):\n",
        "  train_data = datasets.MNIST(\n",
        "      root=path,\n",
        "      download=download,\n",
        "      train = True,\n",
        "      transform = ToTensor()\n",
        "  ) \n",
        "  validation_data = datasets.MNIST(\n",
        "      root=path,\n",
        "      download=download,\n",
        "      train = False,\n",
        "      transform = ToTensor()\n",
        "  ) \n",
        "  return train_data, validation_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "available cuda:0 device \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwVV3AcLrPiK",
        "outputId": "017903bf-ffa0-4eaa-a649-22e9948ab641"
      },
      "source": [
        "train_data , _ = download_mnist_datasets(path=\"/content/drive/MyDrive/Dataset\")\n",
        "print(\"MNIST dataset downloaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST dataset downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "856IuCTxsYXx"
      },
      "source": [
        "BATCH = 128\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_nxkYB3Xq9v",
        "outputId": "e97f84a1-6da6-4101-c1b4-a9268e1f99f2"
      },
      "source": [
        "feed_forward_net = FeedForwardNet()\n",
        "feed_forward_net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedForwardNet(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (dense_layers): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9JO29GsXXKx"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimiser = torch.optim.Adam(feed_forward_net.parameters(), lr =LEARNING_RATE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kZ0F0BZrWPD"
      },
      "source": [
        "# create a dataloader \n",
        "train_data_loader = DataLoader(train_data,batch_size= BATCH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lry2rbMlyg2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd42107-6e17-4864-f731-80e9c3ca2b0d"
      },
      "source": [
        "train(feed_forward_net, train_data_loader, loss_fn,optimiser, device, EPOCHS)\n",
        "torch.save(feed_forward_net.state_dict(), \"/content/drive/MyDrive/Models/Pytorch/feedforward.pth\")\n",
        "print(\"Model Is trained\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss : 1.5054715871810913\n",
            "------------------------\n",
            "epoch 89\n",
            "loss : 1.5050454139709473\n",
            "------------------------\n",
            "epoch 90\n",
            "loss : 1.5046306848526\n",
            "------------------------\n",
            "epoch 91\n",
            "loss : 1.5042308568954468\n",
            "------------------------\n",
            "epoch 92\n",
            "loss : 1.503841757774353\n",
            "------------------------\n",
            "epoch 93\n",
            "loss : 1.5034593343734741\n",
            "------------------------\n",
            "epoch 94\n",
            "loss : 1.5030831098556519\n",
            "------------------------\n",
            "epoch 95\n",
            "loss : 1.5027211904525757\n",
            "------------------------\n",
            "epoch 96\n",
            "loss : 1.5023651123046875\n",
            "------------------------\n",
            "epoch 97\n",
            "loss : 1.502016544342041\n",
            "------------------------\n",
            "epoch 98\n",
            "loss : 1.5016741752624512\n",
            "------------------------\n",
            "epoch 99\n",
            "loss : 1.5013419389724731\n",
            "------------------------\n",
            "epoch 100\n",
            "loss : 1.5010143518447876\n",
            "------------------------\n",
            "training done\n",
            "Model Is trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsy9Ex97iCBx"
      },
      "source": [
        "class_mapping = [\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\"\n",
        "]\n",
        "def predict(model,input, target, class_mapping):\n",
        "  model.eval()            # with this .eval() method, \n",
        "  with torch.no_grad():\n",
        "    predicted = model(input)   # preds are of shape tensor(1,10) -> [[0.1, 0.1, 0.2, 0.89, 0.2,.....]]\n",
        "    predicted_index = predicted[0].argmax(0)\n",
        "    predicted = class_mapping[predicted_index]\n",
        "    expected = class_mapping[target]\n",
        "  return predicted, expected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV5kDCDpbjSv"
      },
      "source": [
        "\n",
        "# inferencing steps\n",
        "#Load back the model\n",
        "feed_forward_instance = FeedForwardNet()\n",
        "state_dict = torch.load(os.path.join(path2,'feedforward.pth'))\n",
        "feed_forward_instance.load_state_dict(state_dict)\n",
        "#get validation data\n",
        "_, validation_data = download_mnist_datasets(path = path1)\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DIcjQxEYAGh",
        "outputId": "f2602899-0637-40ce-f1ce-10a36b133259"
      },
      "source": [
        "validaton_data_loader = DataLoader(validation_data,100)\n",
        "for input , target in validaton_data_loader:\n",
        "  for input , target in zip(input, target):#nput, target = validation_data[0][0], validation_data[0][1]\n",
        "#make inference\n",
        "    preds, expect = predict(feed_forward_instance, input, target, class_mapping)\n",
        "    print(f\"expected {expect} ,predicted {preds}\")\n",
        "    \n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected 7 ,predicted 7\n",
            "expected 2 ,predicted 2\n",
            "expected 1 ,predicted 1\n",
            "expected 0 ,predicted 0\n",
            "expected 4 ,predicted 4\n",
            "expected 1 ,predicted 1\n",
            "expected 4 ,predicted 4\n",
            "expected 9 ,predicted 9\n",
            "expected 5 ,predicted 6\n",
            "expected 9 ,predicted 9\n",
            "expected 0 ,predicted 0\n",
            "expected 6 ,predicted 6\n",
            "expected 9 ,predicted 9\n",
            "expected 0 ,predicted 0\n",
            "expected 1 ,predicted 1\n",
            "expected 5 ,predicted 5\n",
            "expected 9 ,predicted 9\n",
            "expected 7 ,predicted 7\n",
            "expected 3 ,predicted 3\n",
            "expected 4 ,predicted 4\n",
            "expected 9 ,predicted 9\n",
            "expected 6 ,predicted 6\n",
            "expected 6 ,predicted 6\n",
            "expected 5 ,predicted 5\n",
            "expected 4 ,predicted 4\n",
            "expected 0 ,predicted 0\n",
            "expected 7 ,predicted 7\n",
            "expected 4 ,predicted 4\n",
            "expected 0 ,predicted 0\n",
            "expected 1 ,predicted 1\n",
            "expected 3 ,predicted 3\n",
            "expected 1 ,predicted 1\n",
            "expected 3 ,predicted 3\n",
            "expected 4 ,predicted 0\n",
            "expected 7 ,predicted 7\n",
            "expected 2 ,predicted 2\n",
            "expected 7 ,predicted 7\n",
            "expected 1 ,predicted 1\n",
            "expected 2 ,predicted 2\n",
            "expected 1 ,predicted 1\n",
            "expected 1 ,predicted 1\n",
            "expected 7 ,predicted 7\n",
            "expected 4 ,predicted 4\n",
            "expected 2 ,predicted 2\n",
            "expected 3 ,predicted 3\n",
            "expected 5 ,predicted 5\n",
            "expected 1 ,predicted 1\n",
            "expected 2 ,predicted 2\n",
            "expected 4 ,predicted 4\n",
            "expected 4 ,predicted 4\n",
            "expected 6 ,predicted 6\n",
            "expected 3 ,predicted 3\n",
            "expected 5 ,predicted 5\n",
            "expected 5 ,predicted 5\n",
            "expected 6 ,predicted 6\n",
            "expected 0 ,predicted 0\n",
            "expected 4 ,predicted 4\n",
            "expected 1 ,predicted 1\n",
            "expected 9 ,predicted 9\n",
            "expected 5 ,predicted 5\n",
            "expected 7 ,predicted 7\n",
            "expected 8 ,predicted 8\n",
            "expected 9 ,predicted 9\n",
            "expected 3 ,predicted 3\n",
            "expected 7 ,predicted 7\n",
            "expected 4 ,predicted 4\n",
            "expected 6 ,predicted 6\n",
            "expected 4 ,predicted 4\n",
            "expected 3 ,predicted 3\n",
            "expected 0 ,predicted 0\n",
            "expected 7 ,predicted 7\n",
            "expected 0 ,predicted 0\n",
            "expected 2 ,predicted 2\n",
            "expected 9 ,predicted 9\n",
            "expected 1 ,predicted 1\n",
            "expected 7 ,predicted 7\n",
            "expected 3 ,predicted 3\n",
            "expected 2 ,predicted 2\n",
            "expected 9 ,predicted 9\n",
            "expected 7 ,predicted 7\n",
            "expected 7 ,predicted 7\n",
            "expected 6 ,predicted 6\n",
            "expected 2 ,predicted 2\n",
            "expected 7 ,predicted 7\n",
            "expected 8 ,predicted 8\n",
            "expected 4 ,predicted 4\n",
            "expected 7 ,predicted 7\n",
            "expected 3 ,predicted 3\n",
            "expected 6 ,predicted 6\n",
            "expected 1 ,predicted 1\n",
            "expected 3 ,predicted 3\n",
            "expected 6 ,predicted 6\n",
            "expected 9 ,predicted 4\n",
            "expected 3 ,predicted 3\n",
            "expected 1 ,predicted 1\n",
            "expected 4 ,predicted 4\n",
            "expected 1 ,predicted 1\n",
            "expected 7 ,predicted 7\n",
            "expected 6 ,predicted 6\n",
            "expected 9 ,predicted 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9zGxgvwfJ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}