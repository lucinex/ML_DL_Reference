{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing Audio CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4kUprPvXLWc"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import librosa \n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/My Drive/Models/speech_model.h5\"\n",
        "NUM_SAMPLES_TO_CONSIDER =22050  # 1 sec\n",
        "file = '/content/audio/six/00b01445_nohash_0.wav'\n",
        "file2 ='/content/audio/zero/0132a06d_nohash_2.wav'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcf7KL1WhHn0"
      },
      "source": [
        "\n",
        "!mkdir /content/audio\n",
        "!tar xvzf /content/speech_commands_v0.01.tar.gz -C /content/audio\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vZbQMeKXce5"
      },
      "source": [
        "class _KSS:\n",
        "  mappings = ['zero', 'six', 'seven', 'two', 'one', 'three', 'four', 'left', 'stop', 'yes', 'five', 'eight']\n",
        "  model =None\n",
        "  _instance =None\n",
        "\n",
        "  def predict(self, file_path):\n",
        "    #extract MFCCs -> convert 2d array to 4d array (#samples, #segments,#coefs,#channels(1))\n",
        "    #-> make prediction\n",
        "\n",
        "    MFCCs = self.preprocess(file_path)\n",
        "    MFCCs = MFCCs[np.newaxis,...,np.newaxis]\n",
        "\n",
        "    predict = self.model.predict(MFCCs)\n",
        "    predicted_index = np.argmax(predict)\n",
        "    p_keyword = self.mappings[predicted_index]\n",
        "\n",
        "    return p_keyword\n",
        "  def preprocess(self, file_path,n_mfccs =13, n_fft=2048,hop_length =512):\n",
        "    #load audio file \n",
        "    signal, sr = librosa.load(file_path)\n",
        "    #ensure consistancy in audio file\n",
        "    if len(signal)> NUM_SAMPLES_TO_CONSIDER:\n",
        "      signal = signal[:NUM_SAMPLES_TO_CONSIDER]\n",
        "\n",
        "    #extract MFCCs\n",
        "    MFCCs = librosa.feature.mfcc(signal,n_mfcc = n_mfccs, n_fft = n_fft, hop_length = hop_length)\n",
        "    return MFCCs.T\n",
        "\n",
        "def KSS():\n",
        "  #ensure that we only have one instance of kss\n",
        "  if _KSS._instance is None:\n",
        "    _KSS._instance = _KSS()\n",
        "    _KSS.model = keras.models.load_model(MODEL_SAVE_PATH)\n",
        "  return _KSS._instance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei_G4zZggrDr",
        "outputId": "771b995b-ced7-40e5-c966-e5cc4af023f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if __name__=='__main__':\n",
        "  \n",
        "  kss = KSS()\n",
        "  keyword = kss.predict(file2)\n",
        "  print(f\"keyword is {keyword}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keyword is zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t16Zdtuhm6n"
      },
      "source": [
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}